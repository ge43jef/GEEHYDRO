{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAkwCd+txvaRamtGDDA33I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ge43jef/GEEHYDRO/blob/main/task_2correctdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "s1-TZbeRWNwX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "files = glob('FLX*') + glob('era*')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat((pd.read_csv(file)for file in files), ignore_index =True)\n",
        "meteo = pd.DataFrame(\n",
        "            {\"sw\": data.SW_IN_F, \"lw\": data.LW_IN_F,\n",
        "            \"pre\": data.PA_F, \"u10\": data.WS_F,  \"vpd\": data.VPD_F , \"lh\": data.LE_CORR})\n",
        "##meteo"
      ],
      "metadata": {
        "id": "0_8sjrwjZ70D"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# For files starting with 'FLX'\n",
        "flx_data = []\n",
        "for file_path in glob('FLX*'):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], format='%Y%m%d')  # Convert TIMESTAMP column to datetime type\n",
        "    flx_data.append(df[['TIMESTAMP', 'SW_IN_F', 'LW_IN_F', 'PA_F', 'WS_F', 'VPD_F', 'LE_CORR']][1:])  # Extract specific columns and exclude header\n",
        "\n",
        "# Concatenate the FLX dataframes into a single dataframe\n",
        "flx_combined = pd.concat(flx_data)\n",
        "\n",
        "# For files starting with 'era'\n",
        "era_data = []\n",
        "for file_path in glob('era*'):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['date'] = df['system:index'].str.split('_').str[0]  # Extract date part from system:index\n",
        "    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')  # Convert date column to datetime type\n",
        "    era_data.append(df[['date', 'temperature_2m', 'total_precipitation_sum']])  # Extract specific columns\n",
        "\n",
        "# Concatenate the era dataframes into a single dataframe\n",
        "era_combined = pd.concat(era_data)\n",
        "\n",
        "# Merge the two dataframes based on the common columns (TIMESTAMP and date)\n",
        "combined = pd.merge(flx_combined, era_combined, left_on='TIMESTAMP', right_on='date')\n",
        "\n",
        "# Optionally, drop the extra columns (TIMESTAMP and date) if desired\n",
        "combined = combined.drop(['TIMESTAMP', 'date'], axis=1)\n",
        "\n",
        "X = combined.drop('LE_CORR', axis=1)\n",
        "y = combined['LE_CORR']\n",
        "#y\n",
        "#X"
      ],
      "metadata": {
        "id": "RKOMtVHmj79b"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ahdphugsn5GT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}