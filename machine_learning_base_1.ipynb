{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ge43jef/GEEHYDRO/blob/block3/machine_learning_base_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a14f54",
      "metadata": {
        "id": "85a14f54"
      },
      "source": [
        "# Machine learning basics\n",
        "A brief introduction to some of the scientific computing used in this course. In particular the NumPy scientific computing package and its use with python.\n",
        "\n",
        "# Outline\n",
        "- [&nbsp;&nbsp;1.1 Goals](#toc_40015_1.1)\n",
        "- [&nbsp;&nbsp;1.2 Useful References](#toc_40015_1.2)\n",
        "- [2 Vectorization <a name='Python and NumPy'></a>](#toc_40015_2)\n",
        "- [3 Model implication](#toc_40015_3)\n",
        "- [4 Cost function](#toc_40015_4)\n",
        "- [5 Feature scaling](#toc_40015_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cceb50e6",
      "metadata": {
        "id": "cceb50e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# library for interactive slider\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import FloatSlider"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e92fad6",
      "metadata": {
        "id": "8e92fad6"
      },
      "source": [
        "<a name=\"toc_40015_1.1\"></a>\n",
        "## 1.1 Goals\n",
        "In this lab, you will:\n",
        "- learn the vectorization computing using numpy library\n",
        "- learn concepts of some machine learning basics including: training feature examples, training target examples, weight, bias, cost function gradient descent and feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "506d3c24",
      "metadata": {
        "id": "506d3c24"
      },
      "source": [
        "<a name=\"toc_40015_1.2\"></a>\n",
        "## 1.2 Useful References\n",
        "- NumPy Documentation including a basic introduction: [NumPy.org](https://NumPy.org/doc/stable/)\n",
        "- A challenging feature topic: [NumPy Broadcasting](https://NumPy.org/doc/stable/user/basics.broadcasting.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56636803",
      "metadata": {
        "id": "56636803"
      },
      "source": [
        "<a name=\"toc_40015_2\"></a>\n",
        "# 2 Vectorization <a name='Python and NumPy'></a>\n",
        "Vectors, as you will use them in this course, are ordered arrays of numbers. In notation, vectors are denoted with lower case bold letters such as $\\mathbf{x}$.  The elements of a vector are all the same type. A vector does not, for example, contain both characters and numbers. The number of elements in the array is often referred to as the *dimension* though mathematicians may prefer *rank*. The vector shown has a dimension of $n$. The elements of a vector can be referenced with an index. In math settings, indexes typically run from 1 to n. In computer science and these labs, indexing will typically run from 0 to n-1.  In notation, elements of a vector, when referenced individually will indicate the index in a subscript, for example, the $0^{th}$ element, of the vector $\\mathbf{x}$ is $x_0$. Note, the x is not bold in this case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "379887e3",
      "metadata": {
        "id": "379887e3"
      },
      "source": [
        "## Data Creation\n",
        "Data creation routines in NumPy will generally have a first parameter which is the shape of the object. This can either be a single value for a 1-D result or a tuple\n",
        "(n,m,...) specifying the shape of the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2233a66",
      "metadata": {
        "id": "d2233a66"
      },
      "outputs": [],
      "source": [
        "a = np.zeros(4);\n",
        "print(f\"np.zeros(4) :   a = {a}, a shape = {a.shape}, a data type = {a.dtype}\") # Notice the f here\n",
        "a = np.zeros((4,));\n",
        "print(f\"np.zeros(4,) :  a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = np.random.random_sample(4);\n",
        "print(f\"np.random.random_sample(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15346691",
      "metadata": {
        "id": "15346691"
      },
      "outputs": [],
      "source": [
        "a = np.arange(4.);\n",
        "print(f\"np.arange(4.):     a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = np.random.rand(4);\n",
        "print(f\"np.random.rand(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59fc4313",
      "metadata": {
        "id": "59fc4313"
      },
      "outputs": [],
      "source": [
        "a = np.array([5,4,3,2]);\n",
        "print(f\"np.array([5,4,3,2]):  a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
        "a = np.array([5.,4,3,2]);\n",
        "print(f\"np.array([5.,4,3,2]): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef8529ed",
      "metadata": {
        "id": "ef8529ed"
      },
      "source": [
        "## Operations on Vectors\n",
        "**Indexing** means referring to *an element* of an array by its position within the array.\n",
        "**Slicing** means getting a *subset* of elements from an array based on their indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6698c125",
      "metadata": {
        "id": "6698c125"
      },
      "outputs": [],
      "source": [
        "# Indexing\n",
        "#vector indexing operations on 1-D vectors\n",
        "a = np.arange(10)\n",
        "print(a)\n",
        "\n",
        "#access an element\n",
        "print(f\"a[2].shape: {a[2].shape} a[2]  = {a[2]}, Accessing an element returns a scalar\")\n",
        "\n",
        "# access the last element, negative indexes count from the end\n",
        "print(f\"a[-1] = {a[-1]}\")\n",
        "\n",
        "#indexs must be within the range of the vector or they will produce and error\n",
        "# please notice the try...except... structure here\n",
        "try:\n",
        "    c = a[10]\n",
        "except Exception as e:\n",
        "    print(\"The error message you'll see is:\")\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20895103",
      "metadata": {
        "id": "20895103"
      },
      "outputs": [],
      "source": [
        "#vector slicing operations\n",
        "a = np.arange(10)\n",
        "print(f\"a        =  {a}\")\n",
        "\n",
        "#access 5 consecutive elements (start:stop:step)\n",
        "c = a[2:7:1]\n",
        "print(\"a[2:7:1] = \", c)\n",
        "\n",
        "# access 3 elements separated by two\n",
        "c = a[2:7:2]\n",
        "print(\"a[2:7:2] = \", c)\n",
        "\n",
        "# access all elements index 3 and above\n",
        "c = a[3:]\n",
        "print(\"a[3:]    = \", c)\n",
        "\n",
        "# access all elements below index 3\n",
        "c = a[:3]\n",
        "print(\"a[:3]    = \", c)\n",
        "\n",
        "# access all elements\n",
        "c = a[:]\n",
        "print(\"a[:]     = \", c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e27a5c",
      "metadata": {
        "id": "b0e27a5c"
      },
      "source": [
        "## Single vector operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970b8384",
      "metadata": {
        "id": "970b8384"
      },
      "outputs": [],
      "source": [
        "a = np.array([1,2,3,4])\n",
        "print(f\"a             : {a}\")\n",
        "# negate elements of a\n",
        "b = -a\n",
        "print(f\"'b = -a'        : {b}\")\n",
        "\n",
        "# sum all elements of a, returns a scalar\n",
        "b = np.sum(a)\n",
        "print(f\"'b = np.sum(a)' : {b}\")\n",
        "\n",
        "b = np.mean(a)\n",
        "print(f\"'b = np.mean(a)': {b}\")\n",
        "\n",
        "b = a**2\n",
        "print(f\"'b = a**2'      : {b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d878ef8",
      "metadata": {
        "id": "8d878ef8"
      },
      "source": [
        "## Vector Vector element-wise operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a88b03",
      "metadata": {
        "id": "28a88b03"
      },
      "outputs": [],
      "source": [
        "a = np.array([ 1, 2, 3, 4])\n",
        "b = np.array([-1,-2, 3, 4])\n",
        "print(f\"Binary operators work element wise: {a + b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339dd67f",
      "metadata": {
        "id": "339dd67f"
      },
      "source": [
        "## Scalar Vector operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea93a94a",
      "metadata": {
        "id": "ea93a94a"
      },
      "outputs": [],
      "source": [
        "a = np.array([1, 2, 3, 4])\n",
        "\n",
        "# multiply a by a scalar\n",
        "b = 5 * a\n",
        "print(f\"b = 5 * a : {b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5757f845",
      "metadata": {
        "id": "5757f845"
      },
      "source": [
        "## Vector Vector dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd3f280",
      "metadata": {
        "id": "ddd3f280"
      },
      "outputs": [],
      "source": [
        "# test 1-D\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([-1, 4, 3, 2])\n",
        "c = np.dot(a, b)\n",
        "print(f\"np.dot(a, b) = {c}, np.dot(a, b).shape = {c.shape} \")\n",
        "print(f\"a.shape = {a.shape} \")\n",
        "c = np.dot(b, a)\n",
        "print(f\"np.dot(b, a) = {c}, np.dot(a, b).shape = {c.shape} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398131c5",
      "metadata": {
        "id": "398131c5"
      },
      "source": [
        "## Matrix Creation\n",
        "The same functions that created 1-D vectors will create 2-D or n-D arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747fda6e",
      "metadata": {
        "id": "747fda6e"
      },
      "outputs": [],
      "source": [
        "a = np.zeros((2, 5))\n",
        "print(f\"a shape = {a.shape}, a = {a}\")\n",
        "\n",
        "a = np.ones((2, 3))\n",
        "print(f\"a shape = {a.shape}, a = {a}\")\n",
        "\n",
        "a = np.random.random_sample((3, 3))\n",
        "print(f\"a shape = {a.shape}, a = {a}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a7604d",
      "metadata": {
        "id": "a5a7604d"
      },
      "outputs": [],
      "source": [
        "# Indexing\n",
        "#vector indexing operations on matrices\n",
        "a = np.arange(6).reshape(-1, 2)   #reshape is a convenient way to create matrices\n",
        "print(f\"a.shape: {a.shape}, \\na= {a}\")\n",
        "\n",
        "#access an element\n",
        "print(f\"\\na[2,0].shape:{a[2, 0].shape} ,  a[2,0] = {a[2, 0]}\")\n",
        "\n",
        "#access a row\n",
        "print(f\"a[2].shape:{a[2].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9cf25fe",
      "metadata": {
        "id": "b9cf25fe"
      },
      "outputs": [],
      "source": [
        "# Slicing\n",
        "#vector 2-D slicing operations\n",
        "a = np.arange(20).reshape(-1, 10)\n",
        "print(f\"a = \\n{a}\")\n",
        "\n",
        "#access 5 consecutive elements (start:stop:step)\n",
        "print(\"\\na[0, 2:7:1] = \", a[0, 2:7:1], \",  a[0, 2:7:1].shape =\", a[0, 2:7:1].shape, \"a 1-D array\")\n",
        "\n",
        "#access 5 consecutive elements (start:stop:step) in two rows\n",
        "print(\"\\na[:, 2:7:1] = \\n\", a[:, 2:7:1], \",  a[:, 2:7:1].shape =\", a[:, 2:7:1].shape, \"a 2-D array\")\n",
        "\n",
        "# access all elements\n",
        "print(\"\\na[:,:] = \\n\", a[:,:], \",  a[:,:].shape =\", a[:,:].shape)\n",
        "\n",
        "# access all elements in one row (very common usage)\n",
        "print(\"\\na[1,:] = \", a[1,:], \",  a[1,:].shape =\", a[1,:].shape, \"a 1-D array\")\n",
        "# same as\n",
        "print(\"\\na[1]   = \", a[1],   \",  a[1].shape   =\", a[1].shape, \"a 1-D array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9265d957",
      "metadata": {
        "id": "9265d957"
      },
      "source": [
        "<a name=\"toc_40015_3\"></a>\n",
        "# 3 Model implication\n",
        "In this part, we will introduce the concept of training feature examples, training target examples, weight and bias.\n",
        "\n",
        "\n",
        "Below is a summary of some of the notation you will encounter.\n",
        "\n",
        "|General <img width=70/> <br />  Notation  <img width=70/> | Description<img width=350/>| Python (if applicable) |\n",
        "|: ------------|: ------------------------------------------------------------||\n",
        "| $a$ | scalar, non bold                                                      ||\n",
        "| $\\mathbf{a}$ | vector, bold                                                      ||\n",
        "| **Regression** |         |    |     |\n",
        "|  $\\mathbf{x}$ | Training Example feature values   | `x_train` |\n",
        "|  $\\mathbf{y}$  | Training Example  targets   | `y_train`\n",
        "|  $x^{(i)}$, $y^{(i)}$ | $i_{th}$Training Example | `x_i`, `y_i`|\n",
        "| m | Number of training examples | `m`|\n",
        "|  $w$  |  parameter: weight                                 | `w`    |\n",
        "|  $b$           |  parameter: bias                                           | `b`    |\n",
        "| $f_{w,b}(x^{(i)})$ | The result of the model evaluation at $x^{(i)}$ parameterized by $w,b$: $f_{w,b}(x^{(i)}) = wx^{(i)}+b$  | `f_wb` |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318b07aa",
      "metadata": {
        "id": "318b07aa"
      },
      "source": [
        "## Problem Statement\n",
        "This lab will use a simple data set with only two data points - a basin with evaporation rate of 13 mm/d under the average temperature 5.0 degree and a basin with evaporation rate of 25.5 mm/d under the average temperature 15.0 degree. These two points will constitute our *data or training set*.\n",
        "\n",
        "| evaporation rate(mm/d)     | average temperature(degree) |\n",
        "| -------------------| ------------------------ |\n",
        "| 13.0               | 5.0                     |\n",
        "| 25.5               | 15.0                      |\n",
        "\n",
        "You would like to fit a linear regression model through these two points, so you can then predict evaporation rate under other temperature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769f2722",
      "metadata": {
        "id": "769f2722"
      },
      "outputs": [],
      "source": [
        "# x_train is the input variable (average temperature)\n",
        "# y_train is the target (evaporation rate)\n",
        "x_train = np.array([15.0, 5.0])\n",
        "y_train = np.array([25.5, 13.0])\n",
        "print(f\"x_train = {x_train}\")\n",
        "print(f\"y_train = {y_train}\")\n",
        "\n",
        "# number of training examples\n",
        "print(f\"x_train.shape: {x_train.shape}\")\n",
        "m = x_train.shape[0]\n",
        "print(f\"Number of training examples is: {m}\")\n",
        "\n",
        "# the i_th example\n",
        "i = 0 # Change this to 1 to see (x^1, y^1)\n",
        "\n",
        "x_i = x_train[i]\n",
        "y_i = y_train[i]\n",
        "print(f\"(x^({i}), y^({i})) = ({x_i}, {y_i})\")\n",
        "\n",
        "# plot the data\n",
        "# Plot the data points\n",
        "plt.scatter(x_train, y_train, marker='x', c='r')\n",
        "# Set the y-axis label\n",
        "plt.ylabel('temperature (degree)')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('evaporation rate (mm/d)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03171459",
      "metadata": {
        "id": "03171459"
      },
      "source": [
        "## Model function\n",
        "The model function for linear regression (which is a function that maps from `x` to `y`) is represented as\n",
        "\n",
        "$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\n",
        "\n",
        "The formula above is how you can represent straight lines - different values of $w$ and $b$ give you different straight lines on the plot.\n",
        "\n",
        "**Note: You can come back to this cell to adjust the model's w and b parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dff8f8b7",
      "metadata": {
        "id": "dff8f8b7"
      },
      "outputs": [],
      "source": [
        "w = 0.5\n",
        "b = 2\n",
        "print(f\"w: {w}\")\n",
        "print(f\"b: {b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a71d37",
      "metadata": {
        "id": "35a71d37"
      },
      "source": [
        "Now, let's compute the value of $f_{w,b}(x^{(i)})$ for your two data points. You can explicitly write this out for each data point as -\n",
        "\n",
        "for $x^{(0)}$, `f_wb = w * x[0] + b`\n",
        "\n",
        "for $x^{(1)}$, `f_wb = w * x[1] + b`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064e825f",
      "metadata": {
        "id": "064e825f"
      },
      "outputs": [],
      "source": [
        "def compute_model_output(x, w, b):\n",
        "    \"\"\"\n",
        "    Computes the prediction of a linear model\n",
        "    Args:\n",
        "      x (ndarray (m,)): Data, m examples\n",
        "      w,b (scalar)    : model parameters\n",
        "    Returns\n",
        "      y (ndarray (m,)): target values\n",
        "    \"\"\"\n",
        "    m = x.shape[0]\n",
        "    f_wb = np.zeros(m)\n",
        "    for i in range(m):\n",
        "        f_wb[i] = w * x[i] + b\n",
        "\n",
        "    return f_wb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a198f05e",
      "metadata": {
        "id": "a198f05e"
      },
      "outputs": [],
      "source": [
        "tmp_f_wb = compute_model_output(x_train, w, b,)\n",
        "\n",
        "# Plot our model prediction\n",
        "plt.plot(x_train, tmp_f_wb, c='b',label='Our Prediction')\n",
        "\n",
        "# Plot the data points\n",
        "plt.scatter(x_train, y_train, marker='x', c='r',label='Actual Values')\n",
        "\n",
        "# plot the data\n",
        "# Plot the data points\n",
        "plt.scatter(x_train, y_train, marker='x', c='r')\n",
        "# Set the y-axis label\n",
        "plt.ylabel('temperature (degree)')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('evaporation rate (mm/d)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21749426",
      "metadata": {
        "id": "21749426"
      },
      "source": [
        "Now go back to the cell before, let us try experimenting with different values of $w$ and $b$. What should the values be for a line that fits our data?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81ed70b",
      "metadata": {
        "id": "e81ed70b"
      },
      "source": [
        "<a name=\"toc_40015_4\"></a>\n",
        "# 4 Cost function\n",
        "A cost function is a measure of how well a machine learning model performs by quantifying the difference between predicted and actual outputs. Its goal is to be minimized by adjusting the model’s parameters during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a001be05",
      "metadata": {
        "id": "a001be05"
      },
      "outputs": [],
      "source": [
        "def compute_cost(x, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the cost function for linear regression.\n",
        "\n",
        "    Args:\n",
        "      x (ndarray (m,)): Data, m examples\n",
        "      y (ndarray (m,)): target values\n",
        "      w,b (scalar)    : model parameters\n",
        "\n",
        "    Returns\n",
        "        total_cost (float): The cost of using w,b as the parameters for linear regression\n",
        "               to fit the data points in x and y\n",
        "    \"\"\"\n",
        "    # number of training examples\n",
        "    m = x.shape[0]\n",
        "\n",
        "    cost_sum = 0\n",
        "    for i in range(m):\n",
        "        f_wb = w * x[i] + b\n",
        "        cost = (f_wb - y[i]) ** 2\n",
        "        cost_sum = cost_sum + cost\n",
        "    total_cost = (1 / (2 * m)) * cost_sum\n",
        "\n",
        "    return total_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b34b51b",
      "metadata": {
        "id": "2b34b51b"
      },
      "outputs": [],
      "source": [
        "# try different w and b\n",
        "w = 1.0\n",
        "\n",
        "cost = compute_cost(x_train, y_train, w, b,)\n",
        "print(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65980bf6",
      "metadata": {
        "id": "65980bf6"
      },
      "outputs": [],
      "source": [
        "# use the slider control to select the value of w and b\n",
        "%matplotlib notebook\n",
        "x_widget = FloatSlider(min=0.5, max=2.5, step=0.005)\n",
        "y_widget = FloatSlider(min=0.5, max=10.0, step=0.005, value=5.0)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "tmp_f_wb = compute_model_output(x_train, w, b,)\n",
        "line, = ax.plot(x_train, tmp_f_wb, c='b',label='Our Prediction')\n",
        "plt.scatter(x_train, y_train, marker='x', c='r',label='Actual Values')\n",
        "def update(w , b ):\n",
        "    tmp_f_wb = compute_model_output(x_train, w, b,)\n",
        "    line.set_ydata( tmp_f_wb)\n",
        "    fig.canvas.draw_idle()\n",
        "    print(\"Cost value =\" + str(compute_cost(x_train, y_train, w, b,)))\n",
        "interact(update,w=x_widget, b=y_widget);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77d6ab0",
      "metadata": {
        "id": "c77d6ab0"
      },
      "source": [
        "<a name=\"toc_40015_5\"></a>\n",
        "# 5 Feature Scaling\n",
        "This section shows the importance of rescaling the dataset so the features have a similar range.\n",
        "\n",
        "## z-score normalization\n",
        "After z-score normalization, all features will have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "To implement z-score normalization, adjust your input values as shown in this formula:\n",
        "$$x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j} \\tag{4}$$\n",
        "where $j$ selects a feature or a column in the $\\mathbf{X}$ matrix. $µ_j$ is the mean of all the values for feature (j) and $\\sigma_j$ is the standard deviation of feature (j).\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mu_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} x^{(i)}_j \\tag{5}\\\\\n",
        "\\sigma^2_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} (x^{(i)}_j - \\mu_j)^2  \\tag{6}\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af914fe8",
      "metadata": {
        "id": "af914fe8"
      },
      "outputs": [],
      "source": [
        "#Z-score\n",
        "def zscore_normalize_features(X):\n",
        "    \"\"\"\n",
        "    computes  X, zcore normalized by column\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n))     : input data, m examples, n features\n",
        "\n",
        "    Returns:\n",
        "      X_norm (ndarray (m,n)): input normalized by column\n",
        "      mu (ndarray (n,))     : mean of each feature\n",
        "      sigma (ndarray (n,))  : standard deviation of each feature\n",
        "    \"\"\"\n",
        "    # find the mean of each column/feature\n",
        "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
        "    # find the standard deviation of each column/feature\n",
        "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
        "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
        "    X_norm = (X - mu) / sigma\n",
        "\n",
        "    return (X_norm, mu, sigma)\n",
        "\n",
        "#check our work\n",
        "#from sklearn.preprocessing import scale\n",
        "#scale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c38084",
      "metadata": {
        "id": "f0c38084"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "X_train = np.array(data)\n",
        "\n",
        "mu     = np.mean(X_train,axis=0)\n",
        "sigma  = np.std(X_train,axis=0)\n",
        "X_mean = (X_train - mu)\n",
        "X_norm = (X_train - mu)/sigma\n",
        "\n",
        "fig,ax=plt.subplots(1, 3, figsize=(12, 3))\n",
        "ax[0].scatter(X_train[:,0], X_train[:,1])\n",
        "ax[0].set_title(\"unnormalized\")\n",
        "ax[0].set_ylim([-10, 30])\n",
        "ax[0].set_xlim([-5, 2500])\n",
        "#ax[0].axis('equal')\n",
        "\n",
        "ax[1].scatter(X_mean[:,0], X_mean[:,1])\n",
        "ax[1].set_title(r\"X - $\\mu$\")\n",
        "ax[1].set_ylim([-20, 20])\n",
        "ax[1].set_xlim([-500, 1500])\n",
        "#ax[1].axis('equal')\n",
        "\n",
        "ax[2].scatter(X_norm[:,0], X_norm[:,1])\n",
        "ax[2].set_title(r\"Z-score normalized\")\n",
        "#ax[2].axis('equal')\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "fig.suptitle(\"distribution of features before, during, after normalization\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7648eadd",
      "metadata": {
        "id": "7648eadd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff936fd",
      "metadata": {
        "id": "eff936fd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}