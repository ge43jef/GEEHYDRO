{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ge43jef/GEEHYDRO/blob/block3/regression_linear_polynomial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8a6ba1",
      "metadata": {
        "id": "8d8a6ba1"
      },
      "source": [
        "# Scikit-Learn Regression\n",
        "There is an open-source, commercially usable machine learning toolkit called scikit-learn. This toolkit contains implementations of many of the algorithms that you will work with in this course."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d098304",
      "metadata": {
        "id": "9d098304"
      },
      "source": [
        "## Goals\n",
        "In this lab you will:\n",
        "- Utilize  scikit-learn to implement linear regression\n",
        "- Utilize  scikit-learn to implement polynomial regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dd05f06",
      "metadata": {
        "id": "0dd05f06"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import learning_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939c6bd9",
      "metadata": {
        "id": "939c6bd9"
      },
      "source": [
        "## A simple linear regression sample\n",
        "Scikit-learn has the [linear regression model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) which implements a closed-form linear regression.\n",
        "\n",
        "Let's use the data from the early labs - a basin with evaporation rate of 5 mm/d under the average temperature 15.0 degree and a basin with evaporation rate of 13 mm/d under the average temperature 25.5 degree.\n",
        "\n",
        "| evaporation rate(mm/d)     | average temperature(degree) |\n",
        "| -------------------| ------------------------ |\n",
        "| 5.0               | 15.0                      |\n",
        "| 13.0               | 25.5                      |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ceef404",
      "metadata": {
        "id": "5ceef404"
      },
      "source": [
        "### Load the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a33acb1",
      "metadata": {
        "id": "2a33acb1"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([5.0, 15.0])   #features\n",
        "y_train = np.array([13.0, 25.5])   #target value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e0bcad",
      "metadata": {
        "id": "d1e0bcad"
      },
      "source": [
        "### Create and fit the model\n",
        "The code below performs regression using scikit-learn.\n",
        "The first step creates a regression object.\n",
        "The second step utilizes one of the methods associated with the object, `fit`. This performs regression, fitting the parameters to the input data. The toolkit expects a two-dimensional X matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60c9b20",
      "metadata": {
        "id": "d60c9b20"
      },
      "outputs": [],
      "source": [
        "linear_model = LinearRegression()\n",
        "#X must be a 2-D Matrix\n",
        "linear_model.fit(X_train.reshape(-1, 1), y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74277987",
      "metadata": {
        "id": "74277987"
      },
      "source": [
        "### View Parameters\n",
        "The $\\mathbf{w}$ and $\\mathbf{b}$ parameters are referred to as 'coefficients' and 'intercept' in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad0dc5f",
      "metadata": {
        "id": "fad0dc5f"
      },
      "outputs": [],
      "source": [
        "b = linear_model.intercept_\n",
        "w = linear_model.coef_\n",
        "print(f\"w = {w:}, b = {b:0.2f}\")\n",
        "print(f\"'manual' prediction: f_wb = wx+b : {1200*w + b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cd81ec",
      "metadata": {
        "id": "55cd81ec"
      },
      "source": [
        "### Make Predictions\n",
        "\n",
        "Calling the `predict` function generates predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc717f0c",
      "metadata": {
        "id": "cc717f0c"
      },
      "outputs": [],
      "source": [
        "y_pred = linear_model.predict(X_train.reshape(-1, 1))\n",
        "\n",
        "print(\"Prediction on training set:\", y_pred)\n",
        "\n",
        "X_test = np.array([[12]])\n",
        "print(f\"Prediction for evaporation rate under 12 degree: {linear_model.predict(X_test)[0]:0.2f}mm/d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98db1003",
      "metadata": {
        "id": "98db1003"
      },
      "outputs": [],
      "source": [
        "# plot the data\n",
        "# Plot the data points\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "line, = ax.plot(X_train, y_pred, c='b',label='Our Prediction')\n",
        "plt.scatter(X_train, y_train, marker='x', c='r',label='True Value')\n",
        "# Set the y-axis label\n",
        "plt.ylabel('temperature (degree)')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('evaporation rate (mm/d)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79448f5e",
      "metadata": {
        "id": "79448f5e"
      },
      "source": [
        "## An application case in hydrology\n",
        "The [FLUXNET2015](https://fluxnet.org/) Dataset includes data collected at sites from multiple regional flux networks, it provides ecosystem-scale data on CO2, water, and energy exchange between the biosphere and the atmosphere, and other meteorological and biological measurements.\n",
        "\n",
        "In this lab, you will use six variables: incoming shortwave radiation(W m-2), incoming longwave radiation(W m-2), temperature(degree C), pressure(kPa), wind speed(m/s), vapor pressure deficit(hPa) to predict the **latent heat flux(W m-2)**, which is the energy form of the evaporation.\n",
        "\n",
        "| variable     | notation |\n",
        "| -------------------| ------------------------ |\n",
        "| incoming shortwave radiation               | sw                      |\n",
        "| incoming longwave radiation              | lw                      |\n",
        "| temperature               | tmp                      |\n",
        "| pressure               | pre                      |\n",
        "| wind speed               | u10                      |\n",
        "| vapor pressure deficit               | vpd                     |\n",
        "| latent heat flux               | lh                      |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8acf73d1",
      "metadata": {
        "id": "8acf73d1"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('FLX_US-Ne1_FLUXNET2015_SUBSET_DD_2001-2013_1-4.csv' , delimiter=\",\", skipinitialspace=True,  parse_dates=True)\n",
        "\n",
        "meteo = pd.DataFrame(\n",
        "            {\"sw\": data.SW_IN_F, \"lw\": data.LW_IN_F, \"tmp\": data.TA_F,\n",
        "             \"pre\": data.PA_F, \"u10\": data.WS_F,  \"vpd\": data.VPD_F , \"lh\": data.LE_CORR})\n",
        "\n",
        "data_all = np.array(meteo)\n",
        "X = data_all[ : , 0:6]\n",
        "y = data_all[ : , 6]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31645a21",
      "metadata": {
        "id": "31645a21"
      },
      "source": [
        "### Read data and split the data into train and test sample without KFold(cross validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf71e82",
      "metadata": {
        "id": "4bf71e82"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train , y_train)\n",
        "y_pred = linear_model.predict(X_test)\n",
        "\n",
        "# plot the data\n",
        "# Plot the data points\n",
        "fig = plt.figure()\n",
        "fig,ax=plt.subplots(2, 1, figsize=(6, 12), sharey=True)\n",
        "ax[0].plot( y_test, marker='x', c='r',label='True Value')\n",
        "ax[0].plot( y_pred, c='b',label='Our Prediction')\n",
        "ax[0].set(xlabel=\"time (day)\", ylabel=\"evaporation rate (mm/d)\")\n",
        "ax[1].scatter( y_test , y_pred, c='b')\n",
        "z = np.polyfit(y_test , y_pred, 1)\n",
        "y_hat = np.poly1d(z)(y_pred)\n",
        "plt.plot(y_pred, y_hat, \"r--\", lw=2)\n",
        "text = f\"$y={z[0]:0.3f}\\;x{z[1]:+0.3f}$\\n$R^2 = {r2_score(y_test, y_hat):0.3f}$\\n\" \\\n",
        "                   f\"$RMSE = {mean_squared_error(y_test, y_hat, squared=False):0.3f} $ \"\n",
        "plt.gca().text(0.05, 0.95, text, transform=plt.gca().transAxes,\n",
        "                           fontsize=14, verticalalignment='top')\n",
        "plt.ylabel('Predict Value')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('True Value')\n",
        "ax[0].legend()\n",
        "print(\"coefficient of determination R^2 =\",linear_model.score(X_test , y_test.reshape(-1, 1)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8510e426",
      "metadata": {
        "id": "8510e426"
      },
      "source": [
        "### Read data and split the data into train and test sample with KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297c26ff",
      "metadata": {
        "id": "297c26ff"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5)\n",
        "for train, test in kf.split(X):\n",
        "    x_train = X[train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe91397",
      "metadata": {
        "id": "afe91397"
      },
      "outputs": [],
      "source": [
        "for train, test in kf.split(X):\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
        "    linear_model = LinearRegression()\n",
        "    linear_model.fit(X_train , y_train)\n",
        "    y_pred = linear_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac3ff26",
      "metadata": {
        "id": "6ac3ff26"
      },
      "outputs": [],
      "source": [
        "y_pred = linear_model.predict(X_test)\n",
        "# plot the data\n",
        "# Plot the data points\n",
        "fig = plt.figure()\n",
        "fig,ax=plt.subplots(2, 1, figsize=(6, 12), sharey=True)\n",
        "ax[0].plot( y_test, marker='x', c='r',label='True Value')\n",
        "ax[0].plot( y_pred, c='b',label='Our Prediction')\n",
        "ax[0].set(xlabel=\"time (day)\", ylabel=\"evaporation rate (mm/d)\")\n",
        "ax[1].scatter( y_test , y_pred, c='b')\n",
        "z = np.polyfit(y_test , y_pred, 1)\n",
        "y_hat = np.poly1d(z)(y_pred)\n",
        "plt.plot(y_pred, y_hat, \"r--\", lw=2)\n",
        "text = f\"$y={z[0]:0.3f}\\;x{z[1]:+0.3f}$\\n$R^2 = {r2_score(y_test, y_hat):0.3f}$\\n\" \\\n",
        "                   f\"$RMSE = {mean_squared_error(y_test, y_hat, squared=False):0.3f} $ \"\n",
        "plt.gca().text(0.05, 0.95, text, transform=plt.gca().transAxes,\n",
        "                           fontsize=14, verticalalignment='top')\n",
        "plt.ylabel('Predict Value')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('True Value')\n",
        "ax[0].legend()\n",
        "print(\"coefficient of determination R^2 =\",linear_model.score(X_test , y_test.reshape(-1, 1)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb35bd23",
      "metadata": {
        "id": "eb35bd23"
      },
      "outputs": [],
      "source": [
        "# plot scatter: x vs y\n",
        "\n",
        "X_features = ['sw','lw','tmp','pre','u10','vpd']\n",
        "fig,ax=plt.subplots(2, 3, figsize=(12, 12), sharey=True)\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.2,\n",
        "                    hspace=0.2)\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ax[i , j].scatter(X_train[:,3 * i+j],y_train)\n",
        "        ax[i , j].set_xlabel(X_features[3 *i+j])\n",
        "\n",
        "ax[0 , 0].set_ylabel(\"lh\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8abeac2",
      "metadata": {
        "id": "b8abeac2"
      },
      "outputs": [],
      "source": [
        "# plot scatter: x^2 vs y\n",
        "\n",
        "X_features = ['sw','lw','tmp','pre','u10','vpd']\n",
        "fig,ax=plt.subplots(2, 3, figsize=(12, 12), sharey=True)\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.2,\n",
        "                    hspace=0.2)\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ax[i , j].scatter(X_train[:,3 * i+j] **2 ,y_train)\n",
        "        ax[i , j].set_xlabel(X_features[3 *i+j])\n",
        "\n",
        "ax[0 , 0].set_ylabel(\"lh\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49675765",
      "metadata": {
        "id": "49675765"
      },
      "outputs": [],
      "source": [
        "# plot scatter: x^3 vs y\n",
        "\n",
        "X_features = ['sw','lw','tmp','pre','u10','vpd']\n",
        "fig,ax=plt.subplots(2, 3, figsize=(12, 12), sharey=True)\n",
        "plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.9,\n",
        "                    top=0.9,\n",
        "                    wspace=0.2,\n",
        "                    hspace=0.2)\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ax[i , j].scatter(X_train[:,3 * i+j] **3 ,y_train)\n",
        "        ax[i , j].set_xlabel(X_features[3 *i+j])\n",
        "\n",
        "ax[0 , 0].set_ylabel(\"lh\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0a8e7e",
      "metadata": {
        "scrolled": false,
        "id": "5c0a8e7e"
      },
      "outputs": [],
      "source": [
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X[: , 0:3])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train , y_train)\n",
        "y_pred = linear_model.predict(X_test)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig,ax=plt.subplots(2, 1, figsize=(6, 12), sharey=True)\n",
        "ax[0].plot( y_test, marker='x', c='r',label='True Value')\n",
        "ax[0].plot( y_pred, c='b',label='Our Prediction')\n",
        "ax[0].set(xlabel=\"time (day)\", ylabel=\"evaporation rate (mm/d)\")\n",
        "ax[1].scatter( y_test , y_pred, c='b')\n",
        "z = np.polyfit(y_test , y_pred, 1)\n",
        "y_hat = np.poly1d(z)(y_pred)\n",
        "plt.plot(y_pred, y_hat, \"r--\", lw=2)\n",
        "text = f\"$y={z[0]:0.3f}\\;x{z[1]:+0.3f}$\\n$R^2 = {r2_score(y_test, y_hat):0.3f}$\\n\" \\\n",
        "                   f\"$RMSE = {mean_squared_error(y_test, y_hat, squared=False):0.3f} $ \"\n",
        "plt.gca().text(0.05, 0.95, text, transform=plt.gca().transAxes,\n",
        "                           fontsize=14, verticalalignment='top')\n",
        "plt.ylabel('Predict Value')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('True Value')\n",
        "ax[0].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aa192f",
      "metadata": {
        "scrolled": false,
        "id": "54aa192f"
      },
      "outputs": [],
      "source": [
        "# Polynomial regression with k-fold\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X[: , 0:3])\n",
        "\n",
        "for train, test in kf.split(X):\n",
        "    X_train, X_test, y_train, y_test = X_poly[train], X_poly[test], y[train], y[test]\n",
        "    linear_model = LinearRegression()\n",
        "    linear_model.fit(X_train , y_train)\n",
        "    y_pred = linear_model.predict(X_test)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig,ax=plt.subplots(2, 1, figsize=(6, 12), sharey=True)\n",
        "ax[0].plot( y_test, marker='x', c='r',label='True Value')\n",
        "ax[0].plot( y_pred, c='b',label='Our Prediction')\n",
        "ax[0].set(xlabel=\"time (day)\", ylabel=\"evaporation rate (mm/d)\")\n",
        "ax[1].scatter( y_test , y_pred, c='b')\n",
        "z = np.polyfit(y_test , y_pred, 1)\n",
        "y_hat = np.poly1d(z)(y_pred)\n",
        "plt.plot(y_pred, y_hat, \"r--\", lw=2)\n",
        "text = f\"$y={z[0]:0.3f}\\;x{z[1]:+0.3f}$\\n$R^2 = {r2_score(y_test, y_hat):0.3f}$\\n\" \\\n",
        "                   f\"$RMSE = {mean_squared_error(y_test, y_hat, squared=False):0.3f} $ \"\n",
        "plt.gca().text(0.05, 0.95, text, transform=plt.gca().transAxes,\n",
        "                           fontsize=14, verticalalignment='top')\n",
        "plt.ylabel('Predict Value')\n",
        "# Set the x-axis label\n",
        "plt.xlabel('True Value')\n",
        "ax[0].legend()\n",
        "# print(\"coefficient of determination R^2 =\",linear_model.score(X_test , y_test.reshape(-1, 1)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9df876",
      "metadata": {
        "id": "5f9df876"
      },
      "source": [
        "### Please use sklearn function to check the best parameters, and other score metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9911d12e",
      "metadata": {
        "id": "9911d12e"
      },
      "source": [
        "## Another training method\n",
        "A training method with [learning curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html), please use this method with other models.\n",
        "Below is an example with polynomial regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a153984",
      "metadata": {
        "id": "4a153984"
      },
      "outputs": [],
      "source": [
        "train_sizes, train_scores, test_scores = learning_curve(estimator=linear_model, X=X_train, y=y_train,\n",
        "                                                       cv=5, train_sizes=np.linspace(0.1, 1.0, 10))\n",
        "#\n",
        "# Calculate training and test mean and std\n",
        "#\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
        "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
        "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
        "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Training Data Size')\n",
        "plt.ylabel('Model accuracy')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}